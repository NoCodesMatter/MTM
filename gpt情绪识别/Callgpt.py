import os
import json
import base64
# import openai
from datetime import datetime

# è®¾ç½®ä½ çš„ OpenAI API Key
# openai.api_key = "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"
from openai import OpenAI
# client = OpenAI(api_key="sk-TtxIcdKCWgHl1vgvB0C0796b081345E1999a9f2873F39277")
client = OpenAI(
    api_key="sk-TtxIcdKCWgHl1vgvB0C0796b081345E1999a9f2873F39277",
    base_url="https://api.gpt.ge/v1/"
)


def encode_image_to_base64(image_path):
    with open(image_path, "rb") as img_file:
        return base64.b64encode(img_file.read()).decode("utf-8")

def get_image_message_list(image_folder, prompt_text=None):
    message = []

    if not prompt_text:
        prompt_text = (
            "ä»¥ä¸‹æ˜¯ä»ä¸€æ®µè§†é¢‘ä¸­æå–çš„å¤šä¸ªä»£è¡¨æ€§ç”»é¢ï¼Œè¯·åˆ¤æ–­è¿™æ®µè§†é¢‘çš„æ•´ä½“æƒ…ç»ªåŸºè°ƒã€‚\n"
            "ä»joy,anger,sadness,fearå’Œinner peaceè¿™äº”ä¸ªä¸­é€‰ä¸€ä¸ªç±»å‹ä½œä¸ºåŸºè°ƒå†ç»™æè¿°ä¾‹å¦‚ï¼šSadness:slow and emotional R&B song with a groovy beat and smooth synths\n"
            "ä¸è¦è¾“å‡ºå…¶ä»–è§£é‡Šæˆ–å»ºè®®ã€‚"
        )


    message.append({"type": "text", "text": prompt_text})

    for filename in sorted(os.listdir(image_folder)):
        if filename.lower().endswith((".jpg", ".png")):
            image_path = os.path.join(image_folder, filename)
            b64_image = encode_image_to_base64(image_path)
            message.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{b64_image}"
                }
            })

    return message

def analyze_video_emotion_with_gpt(image_folder, save_to_txt=True):
    messages = [
        {"role": "user", "content": get_image_message_list(image_folder)}
    ]

    response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=messages,
        temperature=0.7,
        max_tokens=2048,
        timeout=120
    )

    print(json.dumps(response.model_dump(), indent=2))
    result = response.choices[0].message.content

    if response.choices[0].finish_reason == "length":
        print("â­ï¸ æ­£åœ¨ç»­å†™æœªå®Œæˆå›å¤...")
        # æŠŠå‰é¢çš„ messages åŸæ ·ç»§ç»­å‘
        messages.append({"role": "user", "content": "è¯·ç»§ç»­åˆšæ‰çš„åˆ†æ"})
        continuation = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=messages,
            max_tokens=2048
        )
        result += "\n\nï¼ˆç»­å†™ï¼‰\n" + continuation.choices[0].message.content


    # ä¿å­˜åˆ° .txt æ–‡ä»¶
    if save_to_txt:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = os.path.join(image_folder, f"emotion_analysis_{timestamp}.txt")
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(result)
        print(f"\nâœ… åˆ†æç»“æœå·²ä¿å­˜åˆ°ï¼š{output_path}")

    return result

# ç¤ºä¾‹ç”¨æ³•ï¼ˆæŒ‡å‘ frames_mixed æ–‡ä»¶å¤¹ï¼‰
if __name__ == "__main__":
    # folder_path = "frames_mixed"  
    folder_path = "movement\keyframes_output" 
    # folder_path = "gpt_input_test" 
    result = analyze_video_emotion_with_gpt(folder_path)
    print("\nğŸ¬ åˆ†æç»“æœï¼š\n")
    print(result)
