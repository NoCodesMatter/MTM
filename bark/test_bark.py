from bark import SAMPLE_RATE, generate_audio
from bark.generation import preload_models
import scipy.io.wavfile as wavfile
import numpy as np
# é¢„åŠ è½½æ¨¡å‹ï¼ˆç¬¬ä¸€æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰
print("ğŸ” æ­£åœ¨åŠ è½½ Bark æ¨¡å‹ï¼ˆä»…é¦–æ¬¡ä¸‹è½½ä¼šè¾ƒæ…¢ï¼‰...")
preload_models()
SAMPLE_RATE = 24000

# æ–‡æœ¬è¾“å…¥ï¼ˆä½ å¯ä»¥æ¢æˆä¸­æ–‡è¯•è¯•ï¼‰
text_prompt = """
[singing] Late at night, I think of you, wondering if you miss me too.
[singing] In this city full of lights, you're the only one that feels so right.
[singing] The silence echoes when you're away.
[singing] But your voice brings peace to my day.
"""
segments = [line.strip() for line in text_prompt.strip().split('\n') if line.strip()]
final_audio = []
# ç”ŸæˆéŸ³é¢‘
print("ğŸ§ æ­£åœ¨ç”ŸæˆéŸ³é¢‘...")
for i, segment in enumerate(segments):
    print(f"ğŸ¤ æ­£åœ¨ç”Ÿæˆç¬¬ {i+1} æ®µè¯­éŸ³ï¼š{segment}")
    audio_array = generate_audio(segment)
    final_audio.append(audio_array)
combined_audio = np.concatenate(final_audio)

# ğŸ’¾ ä¿å­˜ä¸º WAV æ–‡ä»¶
output_path = "output.wav"
wavfile.write(output_path, SAMPLE_RATE, combined_audio)
print(f"âœ… ç”Ÿæˆå®Œæˆï¼è¾“å‡ºä¿å­˜ä¸ºï¼š{output_path}")
