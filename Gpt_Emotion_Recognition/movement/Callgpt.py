import os
import json
import base64
import sys
from datetime import datetime
from openai import OpenAI

client = OpenAI(
    api_key="sk-TtxIcdKCWgHl1vgvB0C0796b081345E1999a9f2873F39277",
    base_url="https://api.gpt.ge/v1/"
)

def encode_image_to_base64(image_path):
    with open(image_path, "rb") as img_file:
        return base64.b64encode(img_file.read()).decode("utf-8")

def get_all_image_batches(image_folder, max_images_per_batch=20, prompt_text=None):
    if not prompt_text:
        prompt_text = (
            "ä»¥ä¸‹æ˜¯ä»ä¸€æ®µè§†é¢‘ä¸­æå–çš„å¤šä¸ªä»£è¡¨æ€§ç”»é¢ï¼Œè¯·åˆ¤æ–­è¿™æ®µè§†é¢‘çš„æ•´ä½“æƒ…ç»ªåŸºè°ƒã€‚\n"
            "ä»joy,anger,sadness,fearå’Œinner peaceè¿™äº”ä¸ªä¸­é€‰ä¸€ä¸ªç±»å‹ä½œä¸ºåŸºè°ƒå†ç»™æè¿°ä¾‹å¦‚ï¼šSadness:slow and emotional R&B song with a groovy beat and smooth synths\n"
            "ä¸è¦è¾“å‡ºå…¶ä»–è§£é‡Šæˆ–å»ºè®®ã€‚"
        )

    images = []
    for filename in sorted(os.listdir(image_folder)):
        if filename.lower().endswith((".jpg", ".png")):
            image_path = os.path.join(image_folder, filename)
            b64_image = encode_image_to_base64(image_path)
            images.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{b64_image}"
                }
            })

    # åˆ†æ‰¹
    batches = [images[i:i + max_images_per_batch] for i in range(0, len(images), max_images_per_batch)]
    return [[{"type": "text", "text": prompt_text}] + batch for batch in batches]

def analyze_video_emotion_with_gpt(image_folder, save_to_txt=True):
    all_batches = get_all_image_batches(image_folder)
    result = ""

    for idx, batch_content in enumerate(all_batches):
        print(f"\nğŸš€ æ­£åœ¨å¤„ç†ç¬¬ {idx+1}/{len(all_batches)} æ‰¹...")

        messages = [{"role": "user", "content": batch_content}]
        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=messages,
            temperature=0.7,
            max_tokens=2048,
            timeout=120
        )

        partial_result = response.choices[0].message.content
        result += f"\nğŸ“¦ ç¬¬ {idx+1} æ‰¹ç»“æœï¼š\n{partial_result}\n"

        if response.choices[0].finish_reason == "length":
            print("â­ï¸ æ­£åœ¨ç»­å†™æœªå®Œæˆå›å¤...")
            messages.append({"role": "user", "content": "è¯·ç»§ç»­åˆšæ‰çš„åˆ†æ"})
            continuation = client.chat.completions.create(
                model="gpt-4-turbo",
                messages=messages,
                max_tokens=2048
            )
            result += "\nï¼ˆç»­å†™ï¼‰\n" + continuation.choices[0].message.content

    if save_to_txt:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = os.path.join(image_folder, f"emotion_analysis_{timestamp}.txt")
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(result)
        print(f"\nâœ… åˆ†æç»“æœå·²ä¿å­˜åˆ°ï¼š{output_path}")

    return result

# ğŸ§  å…¥å£ï¼šä»å‘½ä»¤è¡Œè·å–è§†é¢‘åå­æ–‡ä»¶å¤¹
if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("âŒ ç”¨æ³•é”™è¯¯ï¼šè¯·æä¾›å…³é”®å¸§æ–‡ä»¶å¤¹åï¼Œå¦‚ï¼špython Callgpt.py Fear")
        sys.exit(1)

    video_name = sys.argv[1]
    folder_path = os.path.join("keyframes_output", video_name)

    if not os.path.isdir(folder_path):
        print(f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼š{folder_path}")
        sys.exit(1)

    result = analyze_video_emotion_with_gpt(folder_path)
    print("\nğŸ¬ åˆ†æç»“æœï¼š\n")
    print(result)
