import os
import subprocess
import shlex
import ffmpeg
os.environ["PATH"] += os.pathsep + r"E:\tools\ffmpeg\bin"

# åå°æ¥å£
# ===== è°ƒç”¨gptè·å¾—æƒ…æ„Ÿåˆ†æ =====
def call_gpt_emotion(video_path, denoise=False, genre="electronic"):
    current_path = os.path.dirname(os.path.abspath(__file__))

    # è·å–å½“å‰é¡¹ç›®ä¸»æ–‡ä»¶å¤¹çš„è·¯å¾„
    project_root = os.path.dirname(current_path)

    # å¦‚æœéœ€è¦é™å™ªï¼Œå…ˆå¤„ç†è§†é¢‘
    if denoise:
        video_path = denoise_video(video_path)
        print(f"ğŸ”Š ä½¿ç”¨é™å™ªåçš„è§†é¢‘: {video_path}")

    # è½¬åˆ°gptæƒ…ç»ªè¯†åˆ«æ–‡ä»¶å¤¹ï¼Œè¿›è¡Œå…³é”®å¸§æå–
    target_script = os.path.join(project_root, "Gpt_Emotion_Recognition")

    pipeline_path = os.path.join(target_script, "movement", "pipeline.py")
    save_path = os.path.join(target_script, "movement", "save.py")
    gpt_path = os.path.join(target_script, "movement", "Callgpt.py")

    video_name = os.path.splitext(os.path.basename(video_path))[0]
    frame_path = os.path.join(target_script, "movement", "keyframes_output", video_name)

    # è°ƒç”¨pipeline.py
    print("ğŸš€ æ­£åœ¨è¿è¡Œ pipeline.py ...")
    pipeline_result = subprocess.run(["python", pipeline_path, video_path])
    
    if pipeline_result.returncode != 0:
        print("âŒ pipeline.py è¿è¡Œå¤±è´¥ï¼Œä¸­æ­¢æµç¨‹")
        exit(1)
    
    print("âœ… pipeline.py æ‰§è¡Œå®Œæˆ\n")
    
    # è°ƒç”¨save.py
    print("ğŸš€ æ­£åœ¨è¿è¡Œ save.py ...")
    save_result = subprocess.run(["python", save_path, video_path])
    
    if save_result.returncode != 0:
        print("âŒ save.py è¿è¡Œå¤±è´¥")
        exit(1)
    
    print("âœ… æ‰€æœ‰æµç¨‹æ‰§è¡Œå®Œæˆ ğŸ‰")
    
    # è°ƒç”¨Callgpt.py
    print("ğŸš€ æ­£åœ¨è¿è¡Œ Callgpt.py ...")
    gpt_result = subprocess.run(["python", gpt_path, frame_path])
    
    if gpt_result.returncode != 0:
        print("âŒ Callgpt.py è¿è¡Œå¤±è´¥")
        exit(1)
    
    print("âœ… GPTæ‰§è¡Œå®Œæˆ ğŸ‰")

    # è°ƒç”¨test_musicgen
    gen_path = os.path.join(project_root, "audiocraft", "test_musicgen.py")
    text_path = os.path.join(frame_path, "gpt_emotion_analysis.txt")

    with open(text_path, "r", encoding="utf-8") as file:
        lines = file.readlines()
        description = lines[-1].strip()  # å»é™¤æœ«å°¾æ¢è¡Œç¬¦
    
    # å°†éŸ³ä¹é£æ ¼æ·»åŠ åˆ°æè¿°ä¸­
    if genre and genre != "electronic":
        description = f"{description} in {genre} style"
    
    print(f"ğŸµ ä½¿ç”¨æè¿°: '{description}' ç”ŸæˆéŸ³ä¹")
    music_url = music_generate(gen_path, description, frame_path, video_name, video_path)
    return music_url


# è§†é¢‘é™å™ªåŠŸèƒ½
def denoise_video(video_path, output_path=None):
    """ä½¿ç”¨FFmpegå¯¹è§†é¢‘è¿›è¡Œé™å™ªå¤„ç†
    
    Args:
        video_path: è¾“å…¥è§†é¢‘è·¯å¾„
        output_path: è¾“å‡ºè·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ç”Ÿæˆä¸´æ—¶æ–‡ä»¶
        
    Returns:
        å¤„ç†åçš„è§†é¢‘è·¯å¾„
    """
    import tempfile
    if output_path is None:
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp:
            output_path = tmp.name
    
    video_name = os.path.basename(video_path)
    print(f"ğŸ”Š å¯¹è§†é¢‘ {video_name} è¿›è¡Œé™å™ªå¤„ç†...")
    
    try:
        # ä½¿ç”¨é«˜è´¨é‡é™å™ªæ»¤é•œ hqdn3d
        (
            ffmpeg
            .input(video_path)
            .filter('hqdn3d', 4, 3, 6, 4.5)  # äº®åº¦ã€è‰²åº¦ã€æ—¶é—´æ»¤æ³¢å™¨å¼ºåº¦
            .output(output_path, vcodec='libx264', acodec='aac')
            .run(overwrite_output=True, quiet=True)
        )
        print(f"âœ… è§†é¢‘é™å™ªå¤„ç†å®Œæˆ: {output_path}")
        return output_path
    except Exception as e:
        print(f"âŒ è§†é¢‘é™å™ªå¤„ç†å¤±è´¥: {str(e)}")
        return video_path  # å¤±è´¥æ—¶è¿”å›åŸå§‹è§†é¢‘

# ===== è°ƒç”¨clipæƒ…æ„Ÿåˆ†æ =====
def call_clip_emotion(video_path, denoise=False, genre="electronic"):
    current_path = os.path.dirname(os.path.abspath(__file__))

    # è·å–å½“å‰é¡¹ç›®ä¸»æ–‡ä»¶å¤¹çš„è·¯å¾„
    project_root = os.path.dirname(current_path)

    # å¦‚æœéœ€è¦é™å™ªï¼Œå…ˆå¤„ç†è§†é¢‘
    if denoise:
        video_path = denoise_video(video_path)
        print(f"ğŸ”Š ä½¿ç”¨é™å™ªåçš„è§†é¢‘: {video_path}")

    # è½¬åˆ°clipæƒ…ç»ªè¯†åˆ«æ–‡ä»¶å¤¹
    clip_path = os.path.join(project_root, "ClIP_project", "emotion_detect.py")
    video_name = os.path.splitext(os.path.basename(video_path))[0]

    print("ğŸš€ æ­£åœ¨è¿è¡Œ emotion_detect.py ...")
    clip_result = subprocess.run(["python", clip_path, video_path, video_name])
    print(clip_path)

    if clip_result.returncode != 0:
        print("âŒ emotion_detect.py è¿è¡Œå¤±è´¥")
        exit(1)

    print("âœ… æ‰€æœ‰æµç¨‹æ‰§è¡Œå®Œæˆ ğŸ‰")

    text_path = os.path.join(project_root, "ClIP_project", "analysis_output", video_name, "clip_emotion_analysis.txt")
    output_path = os.path.join(project_root, "ClIP_project", "analysis_output", video_name)
    gen_path = os.path.join(project_root, "audiocraft", "test_musicgen.py")

    # è¯»å–æƒ…ç»ªæè¿°ï¼Œè°ƒç”¨generate
    with open(text_path, "r", encoding="utf-8") as file:
        lines = file.readlines()
        description = lines[-1].strip()  # å»é™¤æœ«å°¾æ¢è¡Œç¬¦
    
    # å°†éŸ³ä¹é£æ ¼æ·»åŠ åˆ°æè¿°ä¸­
    if genre and genre != "electronic":
        description = f"{description} in {genre} style"
    
    print(f"ğŸµ ä½¿ç”¨æè¿°: '{description}' ç”ŸæˆéŸ³ä¹")
    music_url = music_generate(gen_path, description, output_path, video_name, video_path)
    return music_url


# è°ƒç”¨music_generateå‡ºéŸ³ä¹
def music_generate(gen_path, description, output_path, video_name, video_path):
    print("ğŸš€ æ­£åœ¨è¿è¡Œ test_musicgen.py ...")
    command = ["python", gen_path, description, output_path, video_name]
    print("ğŸ’» CMD:", " ".join(command))

    result = subprocess.run(command, capture_output=True, text=True)

    print("ğŸ“¤ STDOUT:\n", result.stdout)
    print("âš ï¸ STDERR:\n", result.stderr)

    if result.returncode != 0:
        print("âŒ test_musicgen.py è¿è¡Œå¤±è´¥")
        raise RuntimeError("test_musicgen.py è¿è¡Œå¤±è´¥")

    print("âœ… æ‰€æœ‰æµç¨‹æ‰§è¡Œå®Œæˆ ğŸ‰")

    # æå–è·¯å¾„å¹¶è¿”å›
    music_path = os.path.join(output_path, video_name + ".wav")

    # è°ƒç”¨éŸ³é¢‘å’Œè§†é¢‘åˆæˆ
    final_path = combine_music_video(video_path, video_name, music_path, output_path)

    return {"status": "success", "music_path": final_path}


def combine_music_video(video_path, video_name, music_path, output_path):
    """åˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘ç”Ÿæˆæœ€ç»ˆçš„è§†é¢‘æ–‡ä»¶
    
    Args:
        video_path: åŸå§‹è§†é¢‘è·¯å¾„
        video_name: è§†é¢‘åç§°ï¼ˆä¸å«æ‰©å±•åï¼‰
        music_path: ç”Ÿæˆçš„éŸ³ä¹è·¯å¾„
        output_path: è¾“å‡ºç›®å½•
        
    Returns:
        ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶è·¯å¾„
    """
    final_path = os.path.join(output_path, video_name + ".mp4")
    print("final_path: ", final_path)
    print("video_path: ", video_path)
    print("music_path: ", music_path)
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶å­˜åœ¨
    if not os.path.exists(video_path):
        print(f"âŒ é”™è¯¯: è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        return music_path
    
    if not os.path.exists(music_path):
        print(f"âŒ é”™è¯¯: éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {music_path}")
        return video_path

    try:        # å…ˆæ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æœ‰æ•ˆæ€§
        try:
            audio_probe = ffmpeg.probe(music_path)
            audio_streams = [stream for stream in audio_probe['streams'] if stream['codec_type'] == 'audio']
            if not audio_streams:
                print(f"âš ï¸ è­¦å‘Š: éŸ³é¢‘æ–‡ä»¶ä¸­æ²¡æœ‰éŸ³è½¨: {music_path}")
            else:
                print(f"âœ… éŸ³é¢‘æ–‡ä»¶æœ‰æ•ˆ: {len(audio_streams)} ä¸ªéŸ³è½¨")
                for i, stream in enumerate(audio_streams):
                    print(f"  éŸ³è½¨ {i+1}: {stream.get('codec_name', 'unknown')}, {stream.get('channels', 'unknown')} å£°é“")
        except Exception as e:
            print(f"âš ï¸ æ— æ³•æ¢æµ‹éŸ³é¢‘æ–‡ä»¶: {str(e)}")
            
        # ä½¿ç”¨ç›´æ¥çš„å‘½ä»¤è¡Œè°ƒç”¨ï¼Œè€Œä¸æ˜¯ffmpeg-python API
        cmd = [
            "ffmpeg",
            "-i", video_path,   # è§†é¢‘è¾“å…¥
            "-i", music_path,   # éŸ³é¢‘è¾“å…¥
            "-c:v", "copy",     # å¤åˆ¶è§†é¢‘æµ
            "-c:a", "aac",      # é‡æ–°ç¼–ç éŸ³é¢‘ä¸ºAAC
            "-b:a", "192k",     # éŸ³é¢‘æ¯”ç‰¹ç‡
            "-map", "0:v:0",    # ä»ç¬¬ä¸€ä¸ªè¾“å…¥å–è§†é¢‘
            "-map", "1:a:0",    # ä»ç¬¬äºŒä¸ªè¾“å…¥å–éŸ³é¢‘
            "-map_metadata", "-1",  # å»é™¤å…ƒæ•°æ®
            "-shortest",        # ä½¿ç”¨æœ€çŸ­çš„è¾“å…¥é•¿åº¦
            "-y",               # è¦†ç›–è¾“å‡º
            final_path          # è¾“å‡ºæ–‡ä»¶
        ]
        
        # æ‰“å°å‘½ä»¤ç”¨äºè°ƒè¯•
        print("FFmpeg command:", " ".join(cmd))
        
        # æ‰§è¡Œå‘½ä»¤
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        # æ‰“å°è¾“å‡ºå’Œé”™è¯¯
        print("STDOUT:", result.stdout)
        print("STDERR:", result.stderr)
        
        if result.returncode != 0:
            print(f"âŒ FFmpeg å‘½ä»¤å¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            raise RuntimeError(f"FFmpeg error: {result.stderr}")

        print("âœ… è§†é¢‘å’ŒéŸ³é¢‘åˆæˆæˆåŠŸ: ", final_path)
        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        if os.path.exists(final_path):
            size_bytes = os.path.getsize(final_path)
            print(f"âœ… è¾“å‡ºæ–‡ä»¶å¤§å°: {size_bytes / (1024*1024):.2f} MB")
            
            # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶æ˜¯å¦åŒ…å«éŸ³é¢‘
            try:
                output_probe = ffmpeg.probe(final_path)
                output_audio = [stream for stream in output_probe['streams'] if stream['codec_type'] == 'audio']
                if not output_audio:
                    print(f"âš ï¸ è­¦å‘Š: ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶ä¸­æ²¡æœ‰éŸ³è½¨!")
                else:
                    print(f"âœ… ç”Ÿæˆçš„è§†é¢‘åŒ…å« {len(output_audio)} ä¸ªéŸ³è½¨")
            except Exception as e:
                print(f"âš ï¸ æ— æ³•æ¢æµ‹è¾“å‡ºæ–‡ä»¶: {str(e)}")
        else:
            print("âš ï¸ è­¦å‘Š: è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨!")

        return final_path
    except Exception as e:
        print(f"âŒ è§†é¢‘éŸ³é¢‘åˆæˆå¤±è´¥: {str(e)}")
        # å¤±è´¥æ—¶è¿”å›éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        return music_path

# test case (æ–‡ä»¶åä¸èƒ½åŒ…å«ä¸­æ–‡)
#call_gpt_emotion(r"E:\MTMusic\video_test\14.mp4")
#call_clip_emotion(r"E:\MTMusic\video_test\14.mp4")
def batch_run_emotion(video_dir, video_ids):
    for vid in video_ids:
        video_path = fr"{video_dir}\{vid}.mp4"
        print(f"â–¶ æ­£åœ¨å¤„ç†è§†é¢‘ï¼š{video_path}")
        call_gpt_emotion(video_path)
        call_clip_emotion(video_path)

# è®¾ç½®è·¯å¾„å’Œç¼–å·èŒƒå›´
# video_dir = r"E:\MTMusic\video_test"
# video_ids = list(range(20, 25))  # å¤„ç† 16.mp4 åˆ° 20.mp4

#batch_run_emotion(video_dir, video_ids)
